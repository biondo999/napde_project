{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyDOE in /home/mariano/Documenti/test/base/lib/python3.9/site-packages (0.3.8)\n",
      "Requirement already satisfied: numpy in /home/mariano/Documenti/test/base/lib/python3.9/site-packages (from pyDOE) (1.24.3)\n",
      "Requirement already satisfied: scipy in /home/mariano/Documenti/test/base/lib/python3.9/site-packages (from pyDOE) (1.11.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-22 23:05:50.345589: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-22 23:05:50.355744: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-22 23:05:50.435162: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-22 23:05:50.436424: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-22 23:05:51.235271: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'tensorflow._api.v2.version' from '/home/mariano/Documenti/test/base/lib/python3.9/site-packages/tensorflow/_api/v2/version/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "!pip install pyDOE\n",
    "\n",
    "#you need to add a dataset with GaussJacobiQuadRule_V3 on the right \n",
    "import sys\n",
    "sys.path.insert(1, '/kaggle/input/quadrule')\n",
    "from GaussJacobiQuadRule_V3 import Jacobi, DJacobi, GaussLobattoJacobiWeights, GaussJacobiWeights\n",
    "\n",
    "#import GaussJacobiQuadRule_V3\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.version)\n",
    "#tf.disable_v2_behavior()\n",
    "import pyDOE\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from pyDOE import lhs\n",
    "#from GaussJacobiQuadRule_V3.py import Jacobi, DJacobi, GaussLobattoJacobiWeights, GaussJacobiWeights\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([3 4 5], shape=(3,), dtype=int32)\n",
      "tf.Tensor([7 8 5], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Suppose you have a list of dictionaries\n",
    "data = [\n",
    "    {'feature1': [1, 2], 'feature2': [3, 4, 5]},\n",
    "    {'feature1': [5, 6], 'feature2': [7, 8, 5]}\n",
    "]\n",
    "\n",
    "# Convert the list of dictionaries into a dictionary of tensors\n",
    "# This assumes all the dictionary values have the same shape\n",
    "data_dict = {\n",
    "    key: tf.constant([d[key] for d in data])\n",
    "    for key in data[0].keys()\n",
    "}\n",
    "\n",
    "# Create a dataset from the dictionary\n",
    "dataset = tf.data.Dataset.from_tensor_slices(data_dict)\n",
    "\n",
    "# You can now use the dataset for further processing\n",
    "for element in dataset:\n",
    "    print(element[\"feature2\"])\n",
    "\n",
    "\n",
    "\n",
    "#make this with your features\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3.]\n",
      "[1. 2. 3.]\n",
      "[1. 2. 3.]\n",
      "[1. 2. 3.]\n",
      "[1. 2. 3.]\n"
     ]
    }
   ],
   "source": [
    "def data_generator():\n",
    "    for e in range(5):\n",
    "        x_quad_element = tf.constant([1, 2, 3], dtype=tf.float32)  # Translation of the element as a TensorFlow tensor\n",
    "        data_dict = {\n",
    "            'x_quad_element': x_quad_element,\n",
    "        }\n",
    "        yield data_dict\n",
    "\n",
    "# Create a dataset from the generator\n",
    "dataset = tf.data.Dataset.from_generator(data_generator, output_signature={\n",
    "    'x_quad_element': tf.TensorSpec(shape=(3,), dtype=tf.float32)\n",
    "})\n",
    "\n",
    "# Iterate through the dataset and print 'x_quad_element' for each element\n",
    "for element in dataset:\n",
    "    print(element['x_quad_element'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class parameters:\n",
    "    def __init__(self,LR,Opt_Niter,N_Element,N_testfcn,N_Quad,lossb_weight,a,b):\n",
    "        self.LR = LR\n",
    "        self.Opt_Niter = Opt_Niter + 1\n",
    "        self.Opt_tresh = 2e-32\n",
    "        self.var_form=2\n",
    "        self.N_Element = N_Element\n",
    "        self.N_testfcn = N_testfcn #number of test function\n",
    "        self.N_Quad = N_Quad    #quadrature points \n",
    "        self.lossb_weight = lossb_weight #hyprparameter we may turn it up\n",
    "\n",
    "        #params for the exact sol and boundary term\n",
    "        self.omega = 8*np.pi\n",
    "        self.amp = 1\n",
    "        self.r1 = 80\n",
    "\n",
    "        #ingredients for loss\n",
    "        [self.x_quad, self.w_quad] = GaussLobattoJacobiWeights(N_Quad, 0, 0)\n",
    "        \n",
    "\n",
    "        self.test_quad_element = self.Test_fcn(self.N_testfcn, self.x_quad)\n",
    "        self.d1test_quad_element, self.d2test_quad_element = self.dTest_fcn(self.N_testfcn, self.x_quad)\n",
    "\n",
    "\n",
    "        [self.x_l, self.x_r] = [a, b]     #modify in the future if you want general (a,b) interval\n",
    "        self.delta_x = (self.x_r - self.x_l)/N_Element\n",
    "        self.grid = np.asarray([ self.x_l + i*self.delta_x for i in range(self.N_Element+1)])\n",
    "\n",
    "        #build right side (it doesnt depend on the network)\n",
    "\n",
    "        self.F_ext_total = []\n",
    "        for e in range(self.N_Element):\n",
    "            x_quad_element = self.grid[e] + (self.grid[e+1]-self.grid[e])/2*(self.x_quad+1)  #traslation of the element \n",
    "\n",
    "            jacobian = (self.grid[e+1]-self.grid[e])/2\n",
    "            testfcn_element = np.asarray([ self.Test_f(n,self.x_quad)  for n in range(1, self.N_testfcn+1)])\n",
    "\n",
    "            #this is fh calculated on the real nodal values summed over each real nodal values(which comes form CGL nodes )\n",
    "\n",
    "            f_quad_element = self.f_ext(x_quad_element)\n",
    "            F_ext_element  = jacobian*np.asarray([sum(self.w_quad*f_quad_element*testfcn_element[i]) for i in range(self.N_testfcn)])    \n",
    "            F_ext_element = F_ext_element[:,None] \n",
    "            self.F_ext_total.append(F_ext_element)\n",
    "\n",
    "        self.F_ext_total = np.asarray(self.F_ext_total)\n",
    "\n",
    "\n",
    "        self.X_bound = np.asarray([a,b],dtype=np.float32)[:,None]\n",
    "        self.u_bound   = self.u_exact(self.X_bound)\n",
    "\n",
    "    def u_exact(self,x):\n",
    "        utemp = 0.1*np.sin(self.omega*x) + np.tanh(self.r1*x)\n",
    "        return self.amp*utemp\n",
    "\n",
    "    def f_ext(self,x):\n",
    "        gtemp =  -0.1*(self.omega**2)*np.sin(self.omega*x) - (2*self.r1**2)*(np.tanh(self.r1*x))/((np.cosh(self.r1*x))**2)\n",
    "        return -self.amp*gtemp\n",
    "\n",
    "    def Test_f(self,n,x):\n",
    "        test  = Jacobi(n+1,0,0,x) - Jacobi(n-1,0,0,x)\n",
    "        return test\n",
    "    \n",
    "    def Test_fcn(self, N_test,x):\n",
    "        test_total = []\n",
    "        for n in range(1,N_test+1):  \n",
    "            test  = Jacobi(n+1,0,0,x) - Jacobi(n-1,0,0,x)\n",
    "            test_total.append(test)\n",
    "        return np.asarray(test_total)\n",
    "\n",
    "    def dTest_fcn(self, N_test,x):  #valuete the first and second derivatives of test functions on a point x \n",
    "        d1test_total = []\n",
    "        d2test_total = []\n",
    "        for n in range(1,N_test+1):  \n",
    "            if n==1:\n",
    "                d1test = ((n+2)/2)*Jacobi(n,1,1,x)\n",
    "                d2test = ((n+2)*(n+3)/(2*2))*Jacobi(n-1,2,2,x)\n",
    "                d1test_total.append(d1test)\n",
    "                d2test_total.append(d2test)\n",
    "            elif n==2:\n",
    "                d1test = ((n+2)/2)*Jacobi(n,1,1,x) - ((n)/2)*Jacobi(n-2,1,1,x)\n",
    "                d2test = ((n+2)*(n+3)/(2*2))*Jacobi(n-1,2,2,x)\n",
    "                d1test_total.append(d1test)\n",
    "                d2test_total.append(d2test)    \n",
    "            else:\n",
    "                d1test = ((n+2)/2)*Jacobi(n,1,1,x) - ((n)/2)*Jacobi(n-2,1,1,x)\n",
    "                d2test = ((n+2)*(n+3)/(2*2))*Jacobi(n-1,2,2,x) - ((n)*(n+1)/(2*2))*Jacobi(n-3,2,2,x)\n",
    "                d1test_total.append(d1test)\n",
    "                d2test_total.append(d2test)    \n",
    "        return np.asarray(d1test_total), np.asarray(d2test_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_type_tf=tf.float32\n",
    "float_type_np=np.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-1.42151662e+00]\n",
      "  [-1.01002384e+00]\n",
      "  [-7.64583410e+00]\n",
      "  [ 2.63004706e+00]\n",
      "  [ 5.69885964e+00]\n",
      "  [-9.89962193e-01]\n",
      "  [-1.32092296e+00]\n",
      "  [ 1.56986039e-01]\n",
      "  [ 1.53116698e-01]\n",
      "  [-1.39251152e-02]\n",
      "  [-1.07496275e-02]\n",
      "  [ 7.94073297e-04]\n",
      "  [ 5.08264346e-04]\n",
      "  [-3.16575955e-05]\n",
      "  [-1.73255019e-05]\n",
      "  [ 9.33625645e-07]\n",
      "  [ 4.46546128e-07]\n",
      "  [-2.12149474e-08]\n",
      "  [-9.01475844e-09]\n",
      "  [ 3.83081587e-10]]\n",
      "\n",
      " [[ 8.78545588e-01]\n",
      "  [ 2.64427675e+00]\n",
      "  [ 4.72538535e+00]\n",
      "  [-6.88555258e+00]\n",
      "  [-3.52208895e+00]\n",
      "  [ 2.59175467e+00]\n",
      "  [ 8.16375286e-01]\n",
      "  [-4.10994785e-01]\n",
      "  [-9.46313239e-02]\n",
      "  [ 3.64564249e-02]\n",
      "  [ 6.64363514e-03]\n",
      "  [-2.07891088e-03]\n",
      "  [-3.14124641e-04]\n",
      "  [ 8.28806611e-05]\n",
      "  [ 1.07077491e-05]\n",
      "  [-2.44426361e-06]\n",
      "  [-2.75980646e-07]\n",
      "  [ 5.55414765e-08]\n",
      "  [ 5.57144268e-09]\n",
      "  [-1.00290728e-09]]\n",
      "\n",
      " [[-1.49496924e-13]\n",
      "  [-2.80276643e+01]\n",
      "  [ 1.75312727e-13]\n",
      "  [ 4.11939325e+01]\n",
      "  [-2.03896839e-13]\n",
      "  [-4.11963666e+01]\n",
      "  [ 2.34278178e-13]\n",
      "  [ 4.19948132e+01]\n",
      "  [-2.76401037e-13]\n",
      "  [-4.35696828e+01]\n",
      "  [ 3.24472350e-13]\n",
      "  [ 4.43551224e+01]\n",
      "  [-3.61338043e-13]\n",
      "  [-4.41802764e+01]\n",
      "  [ 4.03608136e-13]\n",
      "  [ 4.32002439e+01]\n",
      "  [-4.26690714e-13]\n",
      "  [-4.15915241e+01]\n",
      "  [ 4.39702615e-13]\n",
      "  [ 3.95166869e+01]]\n",
      "\n",
      " [[-8.78545588e-01]\n",
      "  [ 2.64427675e+00]\n",
      "  [-4.72538535e+00]\n",
      "  [-6.88555258e+00]\n",
      "  [ 3.52208895e+00]\n",
      "  [ 2.59175467e+00]\n",
      "  [-8.16375286e-01]\n",
      "  [-4.10994785e-01]\n",
      "  [ 9.46313239e-02]\n",
      "  [ 3.64564249e-02]\n",
      "  [-6.64363514e-03]\n",
      "  [-2.07891088e-03]\n",
      "  [ 3.14124641e-04]\n",
      "  [ 8.28806611e-05]\n",
      "  [-1.07077491e-05]\n",
      "  [-2.44426361e-06]\n",
      "  [ 2.75980650e-07]\n",
      "  [ 5.55414759e-08]\n",
      "  [-5.57144181e-09]\n",
      "  [-1.00290473e-09]]\n",
      "\n",
      " [[ 1.42151662e+00]\n",
      "  [-1.01002384e+00]\n",
      "  [ 7.64583410e+00]\n",
      "  [ 2.63004706e+00]\n",
      "  [-5.69885964e+00]\n",
      "  [-9.89962193e-01]\n",
      "  [ 1.32092296e+00]\n",
      "  [ 1.56986039e-01]\n",
      "  [-1.53116698e-01]\n",
      "  [-1.39251152e-02]\n",
      "  [ 1.07496275e-02]\n",
      "  [ 7.94073297e-04]\n",
      "  [-5.08264346e-04]\n",
      "  [-3.16575955e-05]\n",
      "  [ 1.73255019e-05]\n",
      "  [ 9.33625646e-07]\n",
      "  [-4.46546131e-07]\n",
      "  [-2.12149476e-08]\n",
      "  [ 9.01476048e-09]\n",
      "  [ 3.83078427e-10]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mariano/Documenti/test/base/lib/python3.9/site-packages/scipy/special/_orthogonal.py:133: RuntimeWarning: invalid value encountered in multiply\n",
      "  np.poly1d.__init__(self, poly.coeffs * float(kn))\n"
     ]
    }
   ],
   "source": [
    "params=parameters(0.001,5000,5,20,100,1,-1,1)\n",
    "\n",
    "print(params.F_ext_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-1.4215167e+00]\n",
      " [-1.0100238e+00]\n",
      " [-7.6458340e+00]\n",
      " [ 2.6300471e+00]\n",
      " [ 5.6988597e+00]\n",
      " [-9.8996222e-01]\n",
      " [-1.3209230e+00]\n",
      " [ 1.5698604e-01]\n",
      " [ 1.5311670e-01]\n",
      " [-1.3925116e-02]\n",
      " [-1.0749628e-02]\n",
      " [ 7.9407328e-04]\n",
      " [ 5.0826435e-04]\n",
      " [-3.1657597e-05]\n",
      " [-1.7325501e-05]\n",
      " [ 9.3362564e-07]\n",
      " [ 4.4654612e-07]\n",
      " [-2.1214948e-08]\n",
      " [-9.0147587e-09]\n",
      " [ 3.8308159e-10]], shape=(20, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 8.7854558e-01]\n",
      " [ 2.6442769e+00]\n",
      " [ 4.7253852e+00]\n",
      " [-6.8855524e+00]\n",
      " [-3.5220890e+00]\n",
      " [ 2.5917547e+00]\n",
      " [ 8.1637532e-01]\n",
      " [-4.1099480e-01]\n",
      " [-9.4631322e-02]\n",
      " [ 3.6456425e-02]\n",
      " [ 6.6436352e-03]\n",
      " [-2.0789108e-03]\n",
      " [-3.1412463e-04]\n",
      " [ 8.2880659e-05]\n",
      " [ 1.0707749e-05]\n",
      " [-2.4442636e-06]\n",
      " [-2.7598065e-07]\n",
      " [ 5.5541477e-08]\n",
      " [ 5.5714429e-09]\n",
      " [-1.0029073e-09]], shape=(20, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-1.4949692e-13]\n",
      " [-2.8027664e+01]\n",
      " [ 1.7531273e-13]\n",
      " [ 4.1193932e+01]\n",
      " [-2.0389684e-13]\n",
      " [-4.1196365e+01]\n",
      " [ 2.3427817e-13]\n",
      " [ 4.1994812e+01]\n",
      " [-2.7640103e-13]\n",
      " [-4.3569683e+01]\n",
      " [ 3.2447236e-13]\n",
      " [ 4.4355122e+01]\n",
      " [-3.6133805e-13]\n",
      " [-4.4180275e+01]\n",
      " [ 4.0360814e-13]\n",
      " [ 4.3200245e+01]\n",
      " [-4.2669072e-13]\n",
      " [-4.1591522e+01]\n",
      " [ 4.3970261e-13]\n",
      " [ 3.9516685e+01]], shape=(20, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-8.7854558e-01]\n",
      " [ 2.6442769e+00]\n",
      " [-4.7253852e+00]\n",
      " [-6.8855524e+00]\n",
      " [ 3.5220890e+00]\n",
      " [ 2.5917547e+00]\n",
      " [-8.1637532e-01]\n",
      " [-4.1099480e-01]\n",
      " [ 9.4631322e-02]\n",
      " [ 3.6456425e-02]\n",
      " [-6.6436352e-03]\n",
      " [-2.0789108e-03]\n",
      " [ 3.1412463e-04]\n",
      " [ 8.2880659e-05]\n",
      " [-1.0707749e-05]\n",
      " [-2.4442636e-06]\n",
      " [ 2.7598065e-07]\n",
      " [ 5.5541477e-08]\n",
      " [-5.5714420e-09]\n",
      " [-1.0029048e-09]], shape=(20, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 1.4215167e+00]\n",
      " [-1.0100238e+00]\n",
      " [ 7.6458340e+00]\n",
      " [ 2.6300471e+00]\n",
      " [-5.6988597e+00]\n",
      " [-9.8996222e-01]\n",
      " [ 1.3209230e+00]\n",
      " [ 1.5698604e-01]\n",
      " [-1.5311670e-01]\n",
      " [-1.3925116e-02]\n",
      " [ 1.0749628e-02]\n",
      " [ 7.9407328e-04]\n",
      " [-5.0826435e-04]\n",
      " [-3.1657597e-05]\n",
      " [ 1.7325501e-05]\n",
      " [ 9.3362564e-07]\n",
      " [-4.4654612e-07]\n",
      " [-2.1214948e-08]\n",
      " [ 9.0147605e-09]\n",
      " [ 3.8307843e-10]], shape=(20, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def data_generator():\n",
    "    for e in range(params.N_Element):\n",
    "\n",
    "        F_ext_element=tf.constant(params.F_ext_total[e], dtype=tf.float32)\n",
    "        Ntest_element=tf.constant(np.shape(F_ext_element)[0])\n",
    "        x_quad_element = tf.constant(params.grid[e] + (params.grid[e+1]-params.grid[e])/2*(params.x_quad+1), dtype=tf.float32)  # Translation of the element as a TensorFlow tensor\n",
    "        jacobian=tf.constant((params.grid[e+1]-params.grid[e])/2,dtype=tf.float32)\n",
    "        x_b_element=tf.constant(np.array([[params.grid[e]], [params.grid[e+1]]]),dtype=tf.float32)\n",
    "        test_quad_element=tf.constant(params.Test_fcn(Ntest_element, params.x_quad),dtype=tf.float32)\n",
    "        d1test_quad_element, d2test_quad_element = tf.constant(params.dTest_fcn(Ntest_element, params.x_quad),dtype=tf.float32)\n",
    "        d1test_bound_element, d2test_bound_element = tf.convert_to_tensor(params.dTest_fcn(Ntest_element, np.array([[-1],[1]])),tf.float32)\n",
    "\n",
    "\n",
    "        data_dict = {\n",
    "            \"F_ext_element\":F_ext_element,  \n",
    "            \"x_quad_element\":x_quad_element,\n",
    "            \"jacobian\":jacobian,\n",
    "            \"x_b_element\":x_b_element,\n",
    "            \"test_quad_element\":test_quad_element,\n",
    "            \"d1test_quad_element\":d1test_quad_element,\n",
    "            \"d2test_quad_element\":d2test_quad_element,\n",
    "            \"d1test_bound_element\":d1test_bound_element,\n",
    "            \"d2test_bound_element\":d2test_bound_element\n",
    "                    }\n",
    "        yield data_dict\n",
    "\n",
    "\n",
    "# Create a dataset from the generator\n",
    "dataset = tf.data.Dataset.from_generator(data_generator, output_signature={\n",
    "    \"F_ext_element\":tf.TensorSpec(shape=(params.N_testfcn,1), dtype=tf.float32),\n",
    "    'x_quad_element': tf.TensorSpec(shape=(params.N_Quad,), dtype=tf.float32),\n",
    "    \"jacobian\":tf.TensorSpec(shape=(), dtype=tf.float32),\n",
    "    \"x_b_element\":tf.TensorSpec(shape=(2,1), dtype=tf.float32),\n",
    "    \"test_quad_element\":tf.TensorSpec(shape=(params.N_testfcn,params.N_Quad), dtype=tf.float32),\n",
    "    \"d1test_quad_element\":tf.TensorSpec(shape=(params.N_testfcn,params.N_Quad), dtype=tf.float32),\n",
    "    \"d2test_quad_element\":tf.TensorSpec(shape=(params.N_testfcn,params.N_Quad), dtype=tf.float32),\n",
    "    \"d1test_bound_element\":tf.TensorSpec(shape=(params.N_testfcn,2,1), dtype=tf.float32),\n",
    "    \"d2test_bound_element\":tf.TensorSpec(shape=(params.N_testfcn,2,1), dtype=tf.float32),\n",
    "})\n",
    "\n",
    "# Iterate through the dataset and print 'x_quad_element' for each element\n",
    "for element in dataset:\n",
    "    print(element[\"F_ext_element\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def grad(x):\n",
    "    with tf.GradientTape() as tape_:\n",
    "        tape_.watch(x)\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(x)\n",
    "            y = model(x)\n",
    "        d1=tape.gradient(y,x)\n",
    "    d2=tape_.gradient(d1,x)\n",
    "    return d2,d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def calculate_loss():\n",
    " varloss_total = 0.0\n",
    " U_NN_element=0.0\n",
    "\n",
    " for element in dataset:\n",
    "\n",
    "    d2u_NN_quad_element,d1u_NN_quad_element=grad(element[\"x_quad_element\"])\n",
    "\n",
    "\n",
    "\n",
    "    if params.var_form == 1:\n",
    "        U_NN_element = tf.reshape(tf.stack([-element[\"jacobian\"]*tf.reduce_sum(params.w_quad*d2u_NN_quad_element*element[\"test_quad_element\"][i]) \\\n",
    "                                        for i in range(params.N_testfcn)]),(-1,1))\n",
    "    \n",
    "        \n",
    "    if params.var_form == 2:\n",
    "        U_NN_element = tf.reshape(tf.stack([tf.reduce_sum(params.w_quad*d1u_NN_quad_element*element[\"d1test_quad_element\"][i]) \\\n",
    "                                        for i in range(params.N_testfcn)]),(-1,1)) \n",
    "\n",
    "    if params.var_form == 3:\n",
    "        u_NN_bound_element=model(element[\"x_b_element\"])\n",
    "        u_NN_quad_element=model(element[\"x_quad_element\"])\n",
    "        U_NN_element = tf.reshape(tf.stack([-1/element[\"jacobian\"]*tf.reduce_sum(params.wquad*u_NN_quad_element*element[\"d2test_quad_element\"][i]) \\\n",
    "                                            +1/element[\"jacobian\"]*tf.reduce_sum(u_NN_bound_element*np.array([-element[\"d1test_bound_element\"][i][0], element[\"d1test_bound_element\"][i][-1]]))  \\\n",
    "                                            for i in range(element[\"Ntest_element\"])]),(-1,1))\n",
    "        \n",
    "        \n",
    "    Res_NN_element = U_NN_element - element[\"F_ext_element\"]\n",
    "    loss_element = tf.reduce_mean(tf.square(Res_NN_element))\n",
    "    varloss_total = varloss_total + loss_element\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " lossb = tf.reduce_mean(tf.square(model(params.X_bound) - params.u_bound))   #u_NN_pred is what your network has calc,while u_tf is the real value\n",
    " return lossb,varloss_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfk=tf.keras\n",
    "tfkl=tf.keras.layers\n",
    "input_shape=(1,)\n",
    "seed=53\n",
    "input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
    "x1 = tfkl.Dense(20, activation=tf.sin, kernel_initializer = tfk.initializers.GlorotUniform(seed))(input_layer)\n",
    "x2 = tfkl.Dense(20, activation=tf.sin, kernel_initializer = tfk.initializers.GlorotUniform(seed))(x1)\n",
    "x3 = tfkl.Dense(20, activation=tf.sin, kernel_initializer = tfk.initializers.GlorotUniform(seed))(x2)\n",
    "x3 = tfkl.Dense(20, activation=tf.sin, kernel_initializer = tfk.initializers.GlorotUniform(seed))(x2)\n",
    "output_layer = tfkl.Dense(1, activation='linear', kernel_initializer = tfk.initializers.GlorotUniform(seed))(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 1)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                40        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                420       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 20)                420       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 901 (3.52 KB)\n",
      "Trainable params: 901 (3.52 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Model(input_layer, output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ciao\n",
      "ciao\n",
      "It: 0, Lossb: 1.204e+00, Lossv: 8.660e+02, Time: 1.10\n",
      "It: 100, Lossb: 2.879e-05, Lossv: 8.660e+02, Time: 26.64\n"
     ]
    }
   ],
   "source": [
    "epochs=1000\n",
    "total_record=[]\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "start_time       = time.time()\n",
    "for epoch in range(epochs+1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(model.trainable_variables)\n",
    "        loss_valueb,loss_valuev=calculate_loss()\n",
    "        loss=loss_valueb*params.lossb_weight+loss_valuev\n",
    "        \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    # Print training loss for this epoch\n",
    "    if (epoch) % 100 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                str_print = 'It: %d, Lossb: %.3e, Lossv: %.3e, Time: %.2f'\n",
    "                print(str_print % (epoch, loss_valueb, loss_valuev, elapsed))\n",
    "                start_time = time.time()        \n",
    "                total_record.append(np.array([epoch, loss,loss_valueb,loss_valuev]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=tf.convert_to_tensor(np.linspace(-1,1,100),tf.float32)\n",
    "y_test=tf.convert_to_tensor(params.u_exact(x_test))\n",
    "\n",
    "\n",
    "u_pred=model(x_test)\n",
    "y_test=tf.expand_dims(y_test,axis=1)\n",
    "\n",
    "fig = plt.figure(0)\n",
    "gridspec.GridSpec(3,1)\n",
    "\n",
    "\n",
    "# plt.savefig('Train-Quad-pnts.pdf')    \n",
    "#++++++++++++++++++++++++++++\n",
    "\n",
    "font = 24\n",
    "#all loss\n",
    "fig, ax = plt.subplots()\n",
    "plt.tick_params(axis='y', which='both', labelleft='on', labelright='off') \n",
    "plt.xlabel('$iteration$', fontsize = font)\n",
    "plt.ylabel('$loss \\,\\, values$', fontsize = font)\n",
    "plt.yscale('log')\n",
    "plt.grid(True)\n",
    "iteration = [total_record[i][0] for i in range(len(total_record))]\n",
    "loss_his  = [total_record[i][1] for i in range(len(total_record))]\n",
    "plt.plot(iteration, loss_his,'green',label=\"loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.tick_params( labelsize = 20)\n",
    "fig.set_size_inches(w=11,h=5.5)\n",
    "plt.show()\n",
    "# plt.savefig('loss.pdf')\n",
    "#++++++++++++++++++++++++++++\n",
    "#partial loss\n",
    "fig, ax = plt.subplots()\n",
    "plt.tick_params(axis='y', which='both', labelleft='on', labelright='off')\n",
    "plt.xlabel('$iteration$', fontsize = font)\n",
    "plt.ylabel('$loss \\,\\, values$', fontsize = font)\n",
    "plt.yscale('log')\n",
    "plt.grid(True)\n",
    "iteration = [total_record[i][0] for i in range(len(total_record))]\n",
    "loss_his  = [total_record[i][1] for i in range(len(total_record))]\n",
    "loss_b  = [total_record[i][2] for i in range(len(total_record))]\n",
    "loss_v  = [total_record[i][3] for i in range(len(total_record))]\n",
    "plt.plot(iteration, loss_his,'green',label=\"loss\")\n",
    "plt.plot(iteration, loss_b,'blue',label=\"boundary_loss\")\n",
    "plt.plot(iteration, loss_v, 'violet',label=\"variational_loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.tick_params( labelsize = 20)\n",
    "fig.set_size_inches(w=11,h=5.5)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "pnt_skip = 25\n",
    "fig, ax = plt.subplots()\n",
    "plt.locator_params(axis='x', nbins=6)\n",
    "plt.locator_params(axis='y', nbins=8)\n",
    "\n",
    "plt.xlabel('$x$', fontsize = font)\n",
    "plt.ylabel('$u$', fontsize = font)\n",
    "plt.axhline(0, linewidth=0.8, linestyle='-', color='gray')\n",
    "for xc in params.grid:\n",
    "    plt.axvline(x=xc, linewidth=2, ls = '--')\n",
    "plt.plot(x_test, y_test, linewidth=1, color='r', label=''.join(['$exact$']))\n",
    "plt.plot(x_test, u_pred, 'k*', label='$VPINN$')\n",
    "plt.tick_params( labelsize = 20)\n",
    "legend = plt.legend(shadow=True, loc='upper left', fontsize=18, ncol = 1)\n",
    "fig.set_size_inches(w=11,h=5.5)\n",
    "plt.show()\n",
    "# plt.savefig('prediction.pdf')\n",
    "#++++++++++++++++++++++++++++\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.locator_params(axis='x', nbins=6)\n",
    "plt.locator_params(axis='y', nbins=8)\n",
    "plt.xlabel('$x$', fontsize = font)\n",
    "plt.ylabel('point-wise error', fontsize = font)\n",
    "plt.yscale('log')\n",
    "plt.axhline(0, linewidth=0.8, linestyle='-', color='gray')\n",
    "for xc in params.grid:\n",
    "    plt.axvline(x=xc, linewidth=2, ls = '--')\n",
    "plt.plot(x_test, abs(y_test - u_pred), 'k')\n",
    "plt.tick_params( labelsize = 20)\n",
    "fig.set_size_inches(w=11,h=5.5)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
