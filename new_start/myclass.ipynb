{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyDOE in /home/mariano/Documenti/test/base/lib/python3.9/site-packages (0.3.8)\n",
      "Requirement already satisfied: numpy in /home/mariano/Documenti/test/base/lib/python3.9/site-packages (from pyDOE) (1.24.3)\n",
      "Requirement already satisfied: scipy in /home/mariano/Documenti/test/base/lib/python3.9/site-packages (from pyDOE) (1.11.1)\n",
      "<module 'tensorflow._api.v2.version' from '/home/mariano/Documenti/test/base/lib/python3.9/site-packages/tensorflow/_api/v2/version/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "!pip install pyDOE\n",
    "\n",
    "#you need to add a dataset with GaussJacobiQuadRule_V3 on the right \n",
    "import sys\n",
    "# sys.path.insert(1, '/kaggle/input/quadrule')\n",
    "from GaussJacobiQuadRule_V3 import Jacobi, DJacobi, GaussLobattoJacobiWeights, GaussJacobiWeights\n",
    "\n",
    "#import GaussJacobiQuadRule_V3\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.version)\n",
    "#tf.disable_v2_behavior()\n",
    "import pyDOE\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from pyDOE import lhs\n",
    "#from GaussJacobiQuadRule_V3.py import Jacobi, DJacobi, GaussLobattoJacobiWeights, GaussJacobiWeights\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 20, 20, 20, 20, 1]\n"
     ]
    }
   ],
   "source": [
    "Net_layer = [1] + [20] * 4 + [1]\n",
    "print(Net_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VPINN:\n",
    "    def __init__(self,Net_layer):\n",
    "\n",
    "        self.layers=Net_layer\n",
    "\n",
    "\n",
    "        self.weights,self.biases=self.initialize_NN(self.layers)\n",
    "\n",
    "        self.variables=[self.weights,self.biases]\n",
    "\n",
    "\n",
    "    def initialize_NN(self,layers):        \n",
    "        weights = []\n",
    "        biases = []\n",
    "        self.layers=layers\n",
    "        num_layers = len(layers) \n",
    "        #transpose everything to have the classic form y=W*x+b \n",
    "        for l in range(0,num_layers-1):\n",
    "\n",
    "            in_dim=layers[l]\n",
    "            out_dim=layers[l+1]\n",
    "\n",
    "            xavier_stddev=np.sqrt(2/(in_dim + out_dim))\n",
    "\n",
    "            W = tf.Variable(tf.random.truncated_normal([out_dim,in_dim], stddev=xavier_stddev,dtype=tf.float64), dtype=tf.float64,trainable=True)\n",
    "            b = tf.Variable(tf.zeros([layers[l+1],1], dtype=tf.float64), dtype=tf.float64,trainable=True)\n",
    "            weights.append(W)\n",
    "            biases.append(b)        \n",
    "        return weights, biases\n",
    "    \n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def neural_net(self,X): #marked for future develop\n",
    "        weights=self.weights\n",
    "        biases=self.biases \n",
    "        num_layers = len(weights) + 1\n",
    "        H = X \n",
    "        for l in range(0,num_layers-2):\n",
    "            W = weights[l]\n",
    "            b = biases[l]\n",
    "            H = tf.sin((W @ H)+b) #change here for having different activation function\n",
    "        W = weights[-1]\n",
    "        b = biases[-1]\n",
    "        Y = (W @ H)+b\n",
    "        return Y\n",
    "    \n",
    "\n",
    "    \n",
    "    @tf.function\n",
    "    def net_du(self,X):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(X)\n",
    "            with tf.GradientTape() as tape_:\n",
    "                tape_.watch(X)\n",
    "                y=self.neural_net(X)\n",
    "            d1=tape_.gradient(y,X)\n",
    "        d2=tape.gradient(d1,X)\n",
    "        return d1,d2\n",
    "    \n",
    "\n",
    "    def predict(self, x):\n",
    "        x=np.array(x)\n",
    "        x=tf.constant(x[:, np.newaxis], dtype=tf.float64)\n",
    "        u_pred  = self.net_du(x)\n",
    "        return u_pred  \n",
    "    \n",
    "\n",
    "    def Test_fcn(self, N_test,x):\n",
    "        test_total = []\n",
    "        for n in range(1,N_test+1):  \n",
    "            test  = Jacobi(n+1,0,0,x) - Jacobi(n-1,0,0,x)\n",
    "            test_total.append(test)\n",
    "        return np.asarray(test_total)\n",
    "\n",
    "    def dTest_fcn(self, N_test,x):  #valuete the first and second derivatives of test functions on a point x \n",
    "        d1test_total = []\n",
    "        d2test_total = []\n",
    "        for n in range(1,N_test+1):  \n",
    "            if n==1:\n",
    "                d1test = ((n+2)/2)*Jacobi(n,1,1,x)\n",
    "                d2test = ((n+2)*(n+3)/(2*2))*Jacobi(n-1,2,2,x)\n",
    "                d1test_total.append(d1test)\n",
    "                d2test_total.append(d2test)\n",
    "            elif n==2:\n",
    "                d1test = ((n+2)/2)*Jacobi(n,1,1,x) - ((n)/2)*Jacobi(n-2,1,1,x)\n",
    "                d2test = ((n+2)*(n+3)/(2*2))*Jacobi(n-1,2,2,x)\n",
    "                d1test_total.append(d1test)\n",
    "                d2test_total.append(d2test)    \n",
    "            else:\n",
    "                d1test = ((n+2)/2)*Jacobi(n,1,1,x) - ((n)/2)*Jacobi(n-2,1,1,x)\n",
    "                d2test = ((n+2)*(n+3)/(2*2))*Jacobi(n-1,2,2,x) - ((n)*(n+1)/(2*2))*Jacobi(n-3,2,2,x)\n",
    "                d1test_total.append(d1test)\n",
    "                d2test_total.append(d2test)    \n",
    "        return np.asarray(d1test_total), np.asarray(d2test_total)\n",
    "    \n",
    "    def Test_f(self,n,x):\n",
    "        test  = Jacobi(n+1,0,0,x) - Jacobi(n-1,0,0,x)\n",
    "        return test\n",
    "\n",
    "    def print_net(self):\n",
    "        for e in range(0,len(self.layers)-1):\n",
    "            print(\"layer \",e, \" :\")\n",
    "            print(self.weights[e])\n",
    "            print(self.biases[e])\n",
    "    \n",
    "    def train(self,nIter,total_record):\n",
    "     #maybe like variables sess.run will do the rest, u(boundary cond) is assigned to u_tf ,x(boundary) is assigned to x_tf and so on\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        lossb_weight=1.0\n",
    "        start_time       = time.time()\n",
    "\n",
    "        for epoch in range(nIter+1):\n",
    "                with tf.GradientTape() as tape:\n",
    "                    tape.watch(self.weights[0])\n",
    "                    loss_valueb,loss_valuev=self.calculate_loss()\n",
    "                loss=loss_valueb*lossb_weight+loss_valuev\n",
    "                \n",
    "                gradients = tape.gradient(loss,self.weights[0])\n",
    "                print(gradients)\n",
    "                optimizer.apply_gradients(zip(gradients,self.weights[0]))\n",
    "            \n",
    "                # Print training loss for this epoch\n",
    "                if (epoch) % 100 == 0:\n",
    "                            elapsed = time.time() - start_time\n",
    "                            str_print = 'It: %d, Lossb: %.3e, Lossv: %.3e, Time: %.2f'\n",
    "                            print(str_print % (epoch, loss_valueb, loss_valuev, elapsed))\n",
    "                            start_time = time.time()        \n",
    "                            total_record.append(np.array([epoch, loss,loss_valueb,loss_valuev]))\n",
    "        return total_record\n",
    "    \n",
    "    def calculate_loss(self):\n",
    "        varloss_total = 0.0\n",
    "        for e in range(N_Element):\n",
    "            F_ext_element  = F_ext_total[e]\n",
    "            Ntest_element  =tf.shape(F_ext_element)[0] #for each element of the grid you have a vector of the focing term (suppose its n-loc),so the you can have at most quad formula n_loc\n",
    "            \n",
    "            x_quad_element = grid[e] + (grid[e+1]-grid[e])/2*(x_quad+1)\n",
    "            #to change change integral to the ref segment in (-1,1)\n",
    "            jacobian= (grid[e+1]-grid[e])/2\n",
    "\n",
    "            x_b_element    = np.array([[grid[e]], [grid[e+1]]])\n",
    "\n",
    "\n",
    "            test_quad_element =tf.constant(self.Test_fcn(Ntest_element, x_quad),dtype=tf.float64)\n",
    "\n",
    "            d1test_quad_element, d2test_quad_element = tf.constant(self.dTest_fcn(Ntest_element,x_quad),dtype=tf.float64)\n",
    "\n",
    "            d1test_bound_element, d2test_bounda_element = tf.constant(self.dTest_fcn(Ntest_element, np.array([[-1],[1]])),dtype=tf.float64)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            U_NN_element = tf.reshape(tf.stack([tf.reduce_sum(w_quad*d1u_NN_quad_element*d1test_quad_element[i]) \\\n",
    "                                                for i in range(Ntest_element)]),(-1,1)) \n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "            Res_NN_element = U_NN_element - F_ext_element\n",
    "            loss_element = tf.reduce_mean(tf.square(Res_NN_element))\n",
    "            varloss_total = varloss_total + loss_element\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        lossb = tf.reduce_mean(tf.square(self.neural_net(X_bound) - u_bound))   #u_NN_pred is what your network has calc,while u_tf is the real value\n",
    "        return lossb,varloss_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_Quad=100\n",
    "N_testfcn=20\n",
    "N_Element=5\n",
    "a=-1.0\n",
    "b=1.0\n",
    "\n",
    "omega = 8*np.pi\n",
    "amp = 1.0\n",
    "r1 = 80.0\n",
    "\n",
    "def u_exact(x):\n",
    "    utemp = 0.1*np.sin(omega*x) + np.tanh(r1*x)\n",
    "    return amp*utemp\n",
    "\n",
    "def f_ext(x):\n",
    "    gtemp =  -0.1*(omega**2)*np.sin(omega*x) - (2*r1**2)*(np.tanh(r1*x))/((np.cosh(r1*x))**2)\n",
    "    return -amp*gtemp\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[x_quad,w_quad] = GaussLobattoJacobiWeights(N_Quad, 0, 0)\n",
    "\n",
    "x_quad=tf.constant([x_quad],dtype=tf.float64)\n",
    "        \n",
    "\n",
    "test_quad_element = model.Test_fcn(N_testfcn,x_quad)\n",
    "d1test_quad_element, d2test_quad_element = model.dTest_fcn(N_testfcn,x_quad)\n",
    "\n",
    "\n",
    "[x_l, x_r] = [a, b]     #modify in the future if you want general (a,b) interval\n",
    "delta_x = (x_r - x_l)/N_Element\n",
    "grid = np.asarray([ x_l + i*delta_x for i in range(N_Element+1)])\n",
    "\n",
    "        #build right side (it doesnt depend on the network)\n",
    "\n",
    "F_ext_total = []\n",
    "for e in range(N_Element):\n",
    "    x_quad_element = grid[e] + (grid[e+1]-grid[e])/2*(x_quad+1)  #traslation of the element \n",
    "\n",
    "    jacobian = (grid[e+1]-grid[e])/2\n",
    "    testfcn_element = np.asarray([ model.Test_f(n,x_quad)  for n in range(1,N_testfcn+1)])\n",
    "\n",
    "    #this is fh calculated on the real nodal values summed over each real nodal values(which comes form CGL nodes )\n",
    "\n",
    "    f_quad_element = f_ext(x_quad_element)\n",
    "    F_ext_element  = jacobian*np.asarray([sum(w_quad*f_quad_element*testfcn_element[i]) for i in range(N_testfcn)])    \n",
    "    F_ext_element = F_ext_element[:,None] \n",
    "    F_ext_total.append(F_ext_element)\n",
    "\n",
    "F_ext_total = np.asarray(F_ext_total)\n",
    "X_bound = np.asarray([a,b],dtype=np.float64)[:,None]\n",
    "u_bound   =u_exact(X_bound)\n",
    "\n",
    "\n",
    "X_bound = tf.constant(np.transpose(X_bound),dtype=tf.float64)\n",
    "u_bound   =tf.constant(np.transpose(u_bound),dtype=tf.float64)\n",
    "\n",
    "F_ext_total=tf.constant(F_ext_total,dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1. 2.]], shape=(1, 2), dtype=float64)\n",
      "tf.Tensor([[0.44571702 0.70008579]], shape=(1, 2), dtype=float64)\n",
      "tf.Tensor([[1. 2.]], shape=(1, 2), dtype=float64)\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function VPINN.neural_net at 0x7f011d478ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor(\n",
      "[[-0.44571702 -0.44544999 -0.44482163 -0.44383345 -0.44248472 -0.44077441\n",
      "  -0.4387012  -0.43626352 -0.4334596  -0.43028746 -0.42674496 -0.42282983\n",
      "  -0.4185397  -0.41387214 -0.4088247  -0.40339499 -0.3975807  -0.39137965\n",
      "  -0.38478988 -0.37780971 -0.37043776 -0.36267308 -0.35451519 -0.34596415\n",
      "  -0.33702064 -0.32768606 -0.31796253 -0.30785307 -0.29736158 -0.28649294\n",
      "  -0.2752531  -0.2636491  -0.25168913 -0.23938259 -0.22674013 -0.21377364\n",
      "  -0.20049632 -0.18692261 -0.17306828 -0.15895031 -0.14458693 -0.12999752\n",
      "  -0.11520259 -0.10022368 -0.08508328 -0.06980472 -0.05441208 -0.03893005\n",
      "  -0.02338381 -0.00779891  0.00779891  0.02338381  0.03893005  0.05441208\n",
      "   0.06980472  0.08508328  0.10022368  0.11520259  0.12999752  0.14458693\n",
      "   0.15895031  0.17306828  0.18692261  0.20049632  0.21377364  0.22674013\n",
      "   0.23938259  0.25168913  0.2636491   0.2752531   0.28649294  0.29736158\n",
      "   0.30785307  0.31796253  0.32768606  0.33702064  0.34596415  0.35451519\n",
      "   0.36267308  0.37043776  0.37780971  0.38478988  0.39137965  0.3975807\n",
      "   0.40339499  0.4088247   0.41387214  0.4185397   0.42282983  0.42674496\n",
      "   0.43028746  0.4334596   0.43626352  0.4387012   0.44077441  0.44248472\n",
      "   0.44383345  0.44482163  0.44544999  0.44571702]], shape=(1, 100), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model=VPINN(Net_layer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input=tf.constant([[1.0,2.0]],dtype=tf.float64)\n",
    "print(input)\n",
    "\n",
    "c=model.neural_net(input)\n",
    "\n",
    "print(c)\n",
    "\n",
    "\n",
    "input=tf.constant([[1.0,2.0]],dtype=tf.float64)\n",
    "print(input)\n",
    "\n",
    "c=model.neural_net(x_quad)\n",
    "\n",
    "print(c)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "float64 float64\n"
     ]
    }
   ],
   "source": [
    "print(test_quad_element.dtype)\n",
    "print(d1test_quad_element.dtype,d2test_quad_element.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(grid.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.00000000e+00 -2.04509619e-05 -1.21754484e-04 ...  2.63252612e-06\n",
      "    1.30336442e-07  0.00000000e+00]]\n",
      "\n",
      " [[ 0.00000000e+00  3.40596651e-05  2.02419924e-04 ...  4.37664158e-06\n",
      "    2.17066346e-07  0.00000000e+00]]\n",
      "\n",
      " [[ 0.00000000e+00 -4.76304942e-05 -2.82331232e-04 ...  6.10445152e-06\n",
      "    3.03554874e-07  0.00000000e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.00000000e+00  2.36659514e-04  1.20581303e-03 ...  2.60716009e-05\n",
      "    1.50825958e-06  0.00000000e+00]]\n",
      "\n",
      " [[ 0.00000000e+00 -2.47660589e-04 -1.23886000e-03 ...  2.67861290e-05\n",
      "    1.57837075e-06  0.00000000e+00]]\n",
      "\n",
      " [[ 0.00000000e+00  2.58388467e-04  1.26742713e-03 ...  2.74037959e-05\n",
      "    1.64674081e-06  0.00000000e+00]]], shape=(20, 1, 100), dtype=float64)\n",
      "tf.Tensor(20, shape=(), dtype=int32)\n",
      "<dtype: 'float64'>\n",
      "tf.Tensor([[-1.  1.]], shape=(1, 2), dtype=float64)\n",
      "tf.Tensor([[-1.  1.]], shape=(1, 2), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(F_ext_total[e])\n",
    "print(tf.shape(F_ext_total[e])[0])\n",
    "print(F_ext_total.dtype)\n",
    "print(X_bound)\n",
    "print(u_bound)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.6        0.60014828 0.60049695 0.60104454 0.60179046 0.60273397\n",
      "  0.60387411 0.60520976 0.60673959 0.60846205 0.61037545 0.61247787\n",
      "  0.61476722 0.6172412  0.61989737 0.62273307 0.62574547 0.62893157\n",
      "  0.6322882  0.63581201 0.63949948 0.64334694 0.64735056 0.65150634\n",
      "  0.65581014 0.66025768 0.66484451 0.66956607 0.67441765 0.67939441\n",
      "  0.68449139 0.68970352 0.69502559 0.7004523  0.70597825 0.71159791\n",
      "  0.7173057  0.72309592 0.7289628  0.73490049 0.74090307 0.74696456\n",
      "  0.75307892 0.75924005 0.76544181 0.77167802 0.77794246 0.78422889\n",
      "  0.79053104 0.79684263 0.80315737 0.80946896 0.81577111 0.82205754\n",
      "  0.82832198 0.83455819 0.84075995 0.84692108 0.85303544 0.85909693\n",
      "  0.86509951 0.8710372  0.87690408 0.8826943  0.88840209 0.89402175\n",
      "  0.8995477  0.90497441 0.91029648 0.91550861 0.92060559 0.92558235\n",
      "  0.93043393 0.93515549 0.93974232 0.94418986 0.94849366 0.95264944\n",
      "  0.95665306 0.96050052 0.96418799 0.9677118  0.97106843 0.97425453\n",
      "  0.97726693 0.98010263 0.9827588  0.98523278 0.98752213 0.98962455\n",
      "  0.99153795 0.99326041 0.99479024 0.99612589 0.99726603 0.99820954\n",
      "  0.99895546 0.99950305 0.99985172 1.        ]], shape=(1, 100), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "x_quad_element = grid[e] + (grid[e+1]-grid[e])/2*(x_quad+1)\n",
    "\n",
    "print(x_quad_element)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m total_record\u001b[39m=\u001b[39m[]\n\u001b[0;32m----> 2\u001b[0m total_record\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39;49mtrain(\u001b[39m5000\u001b[39;49m,total_record)\n",
      "Cell \u001b[0;32mIn[20], line 121\u001b[0m, in \u001b[0;36mVPINN.train\u001b[0;34m(self, nIter, total_record)\u001b[0m\n\u001b[1;32m    119\u001b[0m gradients \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39mgradient(loss,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights[\u001b[39m0\u001b[39m])\n\u001b[1;32m    120\u001b[0m \u001b[39mprint\u001b[39m(gradients)\n\u001b[0;32m--> 121\u001b[0m optimizer\u001b[39m.\u001b[39mapply_gradients(\u001b[39mzip\u001b[39;49m(gradients,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweights[\u001b[39m0\u001b[39;49m]))\n\u001b[1;32m    123\u001b[0m \u001b[39m# Print training loss for this epoch\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39mif\u001b[39;00m (epoch) \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "total_record=[]\n",
    "total_record=model.train(5000,total_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[<tf.Variable 'Variable:0' shape=(20, 1) dtype=float64, numpy=\n",
      "array([[ 0.33419472],\n",
      "       [ 0.27755291],\n",
      "       [-0.09805934],\n",
      "       [ 0.40352766],\n",
      "       [-0.00509879],\n",
      "       [ 0.10950405],\n",
      "       [-0.05277721],\n",
      "       [ 0.06969386],\n",
      "       [ 0.32769571],\n",
      "       [ 0.04114216],\n",
      "       [-0.03858022],\n",
      "       [ 0.29587913],\n",
      "       [ 0.21606287],\n",
      "       [-0.06228451],\n",
      "       [-0.20560043],\n",
      "       [-0.01487679],\n",
      "       [-0.365012  ],\n",
      "       [-0.61200223],\n",
      "       [ 0.16868443],\n",
      "       [ 0.21724071]])>, <tf.Variable 'Variable:0' shape=(20, 20) dtype=float64, numpy=\n",
      "array([[-1.36813727e-01,  2.09748106e-01, -1.63044257e-02,\n",
      "        -2.68833695e-01,  8.12093257e-03,  1.95084805e-01,\n",
      "        -7.99277993e-02,  1.17006413e-01,  4.51607797e-02,\n",
      "         1.10786714e-01,  3.14859786e-01, -2.28553717e-01,\n",
      "        -3.73195404e-02, -2.67942230e-02,  1.24504948e-01,\n",
      "         2.25323211e-01, -2.05892488e-01,  6.44971595e-02,\n",
      "         1.70326251e-01,  4.34812760e-03],\n",
      "       [-3.89187652e-01,  4.99648596e-02,  2.83280130e-01,\n",
      "         3.25136140e-01, -8.16662241e-02, -1.72988967e-01,\n",
      "         2.12750176e-02, -5.50345320e-02, -2.34823800e-01,\n",
      "        -2.25154460e-01, -3.64445948e-01,  4.06850809e-01,\n",
      "         1.69512935e-01,  1.29107072e-01, -1.04235041e-01,\n",
      "        -3.07390468e-01,  3.68768942e-02, -2.03523420e-01,\n",
      "         3.01226941e-01, -2.58152056e-01],\n",
      "       [ 1.02918542e-01, -7.63989322e-02, -1.16870411e-01,\n",
      "         8.69598319e-02,  2.99573336e-01,  1.58440808e-01,\n",
      "        -8.61155341e-02, -2.57860981e-01,  5.17427467e-02,\n",
      "        -1.65036752e-01, -1.57843013e-01, -2.45413517e-01,\n",
      "         3.44034680e-01, -4.69086341e-02, -2.97102684e-01,\n",
      "         7.02185225e-02, -1.44059816e-01, -3.97762100e-02,\n",
      "        -1.96770697e-01, -4.01376404e-02],\n",
      "       [-2.26620448e-01, -1.46509124e-01, -2.33409367e-01,\n",
      "        -1.20627885e-01, -7.95911659e-02, -9.28916387e-02,\n",
      "         9.58193671e-02, -1.18847341e-02, -2.95510696e-02,\n",
      "        -1.92222084e-01, -5.88409008e-02,  5.95518432e-02,\n",
      "        -4.66454540e-02, -1.40913672e-02,  6.96249331e-02,\n",
      "         2.75166642e-01, -1.75353523e-01, -3.69454036e-01,\n",
      "         3.45108878e-01,  2.17911769e-01],\n",
      "       [-1.30093770e-01,  8.63987397e-02, -1.32901574e-01,\n",
      "         2.12711572e-03,  3.13519852e-02, -1.31756139e-01,\n",
      "         1.75677640e-01, -1.68121827e-01, -1.23854574e-01,\n",
      "        -1.48665646e-01, -2.77639745e-01, -9.86109538e-02,\n",
      "        -6.89393995e-02,  1.25044841e-01, -1.33805262e-01,\n",
      "         7.53478396e-03, -1.82125322e-01, -2.80489039e-01,\n",
      "         3.48945860e-01, -2.10252758e-02],\n",
      "       [ 9.03102668e-02, -4.06263053e-02, -1.68440491e-01,\n",
      "         1.80510704e-01, -2.32498443e-01,  9.07478556e-03,\n",
      "        -3.14549323e-01, -3.69292128e-02, -4.71954703e-03,\n",
      "         7.91908057e-02, -2.00031712e-01,  2.05699677e-01,\n",
      "        -9.22700143e-02, -9.98920598e-03,  4.18376510e-01,\n",
      "         2.42864822e-01,  1.58563872e-01,  1.87234429e-01,\n",
      "         2.09630877e-01,  7.25935212e-02],\n",
      "       [ 1.88155838e-01, -7.22261139e-02,  5.25035265e-02,\n",
      "        -2.57560535e-01,  3.83118250e-01, -1.28021546e-01,\n",
      "        -3.74333216e-02,  1.49514715e-01,  4.31961475e-01,\n",
      "         5.47710245e-02, -5.90026924e-02, -6.91672027e-02,\n",
      "         4.29401991e-02, -1.79510623e-01,  1.61818055e-01,\n",
      "        -1.85602628e-01,  1.45902621e-01,  4.31608716e-01,\n",
      "        -2.94752898e-01, -2.45641347e-01],\n",
      "       [-2.64706339e-01,  2.30892799e-01,  1.06203602e-01,\n",
      "         6.17929656e-02,  9.34502551e-02,  1.69506357e-01,\n",
      "        -4.82653340e-02, -5.13962645e-03,  2.13295559e-01,\n",
      "         1.63138080e-01, -7.05412687e-02,  2.36215141e-01,\n",
      "        -3.91987453e-01, -4.81875997e-02,  5.45219287e-02,\n",
      "        -9.08094183e-02, -2.46543320e-01,  1.23585350e-01,\n",
      "        -1.18534972e-01, -6.04569916e-02],\n",
      "       [-3.34415015e-02,  3.20355364e-01, -8.61872610e-02,\n",
      "         3.75908907e-02,  1.13867995e-01,  8.49159729e-02,\n",
      "        -7.27092845e-02, -5.21403145e-02,  1.52417544e-01,\n",
      "         1.99250577e-01,  5.18031188e-02,  2.05924210e-01,\n",
      "         9.87824326e-02, -1.52144833e-02, -2.39073582e-01,\n",
      "         5.05804229e-02,  1.49565776e-01,  4.66733584e-02,\n",
      "         1.38841801e-01,  3.48288565e-01],\n",
      "       [-2.44191197e-01,  3.66830586e-02,  2.57633321e-02,\n",
      "         1.64669500e-01,  1.60553115e-01, -4.71854937e-02,\n",
      "         3.69378850e-02,  1.63178282e-01, -1.28375830e-01,\n",
      "        -9.92332332e-02, -1.88716174e-01, -2.98746623e-01,\n",
      "        -9.95223319e-02, -2.21359110e-02,  1.82804408e-01,\n",
      "         4.07672026e-01,  9.15007626e-02, -9.45041642e-02,\n",
      "         5.79021285e-02, -5.73039542e-02],\n",
      "       [ 1.64196909e-01,  1.43616159e-01, -1.02370608e-01,\n",
      "         2.38389287e-01,  6.20399987e-02, -1.14368822e-01,\n",
      "        -5.84597668e-02, -1.36578545e-01,  1.35802748e-01,\n",
      "        -1.76439367e-01,  2.12390565e-01, -2.11210415e-01,\n",
      "         4.17797223e-01,  3.44083260e-03, -1.70681272e-01,\n",
      "        -1.18305859e-01,  1.90369134e-01,  4.11100689e-02,\n",
      "        -1.66683384e-01,  2.13899874e-02],\n",
      "       [ 9.43477194e-02,  2.98525785e-01, -3.84526457e-01,\n",
      "        -1.47778220e-01, -1.56107543e-01,  8.34464676e-02,\n",
      "        -1.51139574e-01,  9.69580017e-03,  1.68227281e-01,\n",
      "         5.76876507e-03,  2.09745424e-02,  5.49314062e-02,\n",
      "        -3.92877429e-01, -4.63983789e-02,  4.12714834e-01,\n",
      "         1.19184043e-01,  2.50617583e-01,  1.40332305e-01,\n",
      "        -3.10524550e-01,  3.23770818e-02],\n",
      "       [ 2.63664142e-01, -4.19871039e-02, -2.75501402e-01,\n",
      "        -2.33850796e-01,  4.55889934e-02, -2.75043945e-01,\n",
      "        -4.00179477e-03,  3.39039582e-01, -2.03571041e-01,\n",
      "        -4.03023799e-01, -2.74734427e-01, -9.31929785e-02,\n",
      "        -2.13403725e-01,  7.82929484e-02, -4.16415912e-01,\n",
      "        -5.06108690e-02,  9.90797969e-03,  2.25954322e-02,\n",
      "         2.35790779e-01,  8.03946061e-02],\n",
      "       [-1.60462165e-01, -5.02207328e-02,  9.74404554e-02,\n",
      "        -1.58059194e-01, -8.41102695e-02,  6.40714059e-02,\n",
      "         9.16307852e-03, -1.31626573e-01, -4.23752066e-02,\n",
      "         1.15424567e-01, -5.46748951e-03,  8.41824022e-03,\n",
      "         1.41103967e-01,  2.52044824e-02, -8.98609371e-02,\n",
      "        -1.07535756e-01,  4.86007994e-02, -1.90421473e-01,\n",
      "        -9.50004274e-02,  2.22327899e-01],\n",
      "       [ 3.27585190e-02,  4.70474599e-02,  1.85658479e-01,\n",
      "        -2.18606310e-01, -9.45654082e-02,  3.17959545e-01,\n",
      "        -1.13851995e-01, -1.76928068e-01, -1.42681205e-01,\n",
      "        -2.09374769e-01, -1.20548829e-01, -2.25602408e-01,\n",
      "        -2.89723070e-01,  2.16796662e-01,  9.72835159e-03,\n",
      "        -8.29796529e-03, -7.93100379e-03,  3.52551773e-01,\n",
      "         4.94503165e-02,  6.98430719e-02],\n",
      "       [-9.24489808e-02, -2.77776397e-01, -1.17189709e-01,\n",
      "        -5.07681706e-05,  3.79102696e-02, -6.80133049e-02,\n",
      "        -1.66625197e-01,  2.92140340e-01,  6.03406783e-02,\n",
      "        -1.15759611e-01, -2.06540855e-02,  3.75043591e-01,\n",
      "        -2.78730575e-01, -2.94562810e-01,  2.24614392e-01,\n",
      "        -5.62253729e-02,  1.76623124e-01,  2.55853970e-01,\n",
      "         4.10912166e-02,  2.15798572e-02],\n",
      "       [-1.82883283e-01, -2.72743592e-01, -6.00669449e-02,\n",
      "         5.52076112e-02, -4.69583156e-02,  5.71665493e-02,\n",
      "         1.06993744e-01, -1.18197705e-01, -5.50842400e-03,\n",
      "         5.48893265e-02, -7.89496257e-02, -1.29356819e-01,\n",
      "        -1.30096107e-01, -3.17546320e-01,  1.36872059e-01,\n",
      "         3.37424225e-02, -2.65623814e-02,  2.49736400e-01,\n",
      "         1.23379385e-01, -1.73744720e-01],\n",
      "       [-1.09171689e-01,  1.41776193e-01,  1.37343161e-01,\n",
      "         3.29887371e-01,  7.87871960e-02,  1.39741068e-01,\n",
      "         3.64280893e-01,  1.87207665e-01,  4.49637578e-02,\n",
      "         1.68409940e-01, -7.17723302e-02,  1.90439703e-01,\n",
      "         3.50885966e-01,  1.40426344e-01,  3.16426353e-01,\n",
      "         3.78684173e-02,  1.88790475e-02, -1.25636460e-01,\n",
      "        -1.74190056e-01,  1.56851692e-01],\n",
      "       [-3.26504573e-01, -8.41488864e-02,  2.93007229e-01,\n",
      "         2.55535876e-01,  7.64320950e-02,  3.38911739e-01,\n",
      "         3.94359800e-03, -1.17610904e-01,  9.38696341e-02,\n",
      "        -3.37461905e-01,  2.65271463e-01,  3.29398571e-02,\n",
      "         2.22350190e-01,  1.66366166e-02,  1.71321178e-01,\n",
      "         7.07103310e-02, -1.95777499e-02,  1.03138180e-01,\n",
      "        -4.45724322e-01,  2.17954620e-01],\n",
      "       [-2.15945676e-02,  1.99675741e-01, -2.51451631e-01,\n",
      "         2.56366571e-01,  4.94877532e-02, -1.15791536e-01,\n",
      "         3.07447563e-01, -1.98055328e-01, -1.99714182e-01,\n",
      "        -1.15832844e-01,  2.41988408e-01, -1.65706069e-01,\n",
      "        -3.13029461e-01, -1.17644197e-01,  1.86242285e-01,\n",
      "         1.25330464e-01, -2.70763591e-01,  3.81389111e-01,\n",
      "        -1.67461017e-01,  3.02487686e-01]])>, <tf.Variable 'Variable:0' shape=(20, 20) dtype=float64, numpy=\n",
      "array([[-0.1890798 , -0.1761752 ,  0.03576449,  0.02455826, -0.34779588,\n",
      "        -0.00275893, -0.22234566, -0.1744468 ,  0.06910627, -0.07019057,\n",
      "         0.35767341, -0.36027052,  0.1669241 ,  0.11712547,  0.04481933,\n",
      "         0.16932867, -0.32179503, -0.09691324,  0.23278686,  0.1416435 ],\n",
      "       [-0.32495922,  0.09808483,  0.07692623, -0.02425026, -0.07122983,\n",
      "         0.08157564,  0.15941388, -0.25951438,  0.32896369,  0.20785655,\n",
      "        -0.04105385,  0.22864633,  0.0130849 ,  0.1654263 , -0.13598454,\n",
      "         0.0804395 , -0.21969148,  0.00848738, -0.06165245,  0.18406877],\n",
      "       [-0.16270179, -0.07367604, -0.14918165,  0.00155073, -0.0161615 ,\n",
      "         0.23002395,  0.13497217, -0.25909898,  0.20406757,  0.15341517,\n",
      "        -0.18779203, -0.23931852, -0.23585589,  0.05347329,  0.07325342,\n",
      "        -0.04755875,  0.15895972,  0.05206114, -0.16005524, -0.0888117 ],\n",
      "       [ 0.13035577, -0.03271637,  0.0767519 ,  0.03676703, -0.04333717,\n",
      "        -0.18009278,  0.21668167, -0.06359608,  0.03911124, -0.03483516,\n",
      "        -0.02103156, -0.25764631, -0.03791212,  0.20689262, -0.03381131,\n",
      "         0.21037016, -0.23666512, -0.06702038,  0.25337514,  0.13323519],\n",
      "       [ 0.06606506, -0.35996335, -0.09100336,  0.0773942 , -0.31157961,\n",
      "        -0.26694088, -0.16679871,  0.15090899, -0.31184928, -0.37547821,\n",
      "        -0.36642137,  0.03081261, -0.04424404, -0.16207224, -0.03626008,\n",
      "         0.04608544, -0.22831223, -0.22665671, -0.37280421,  0.10597747],\n",
      "       [ 0.01625214, -0.06630806, -0.04874507,  0.15302145, -0.25938509,\n",
      "         0.19066557, -0.1974675 ,  0.24953588,  0.01451314, -0.00682369,\n",
      "         0.37089731, -0.2849407 , -0.06651315,  0.31775033,  0.00907982,\n",
      "        -0.10827761, -0.08677665,  0.22835824,  0.06491267, -0.04080781],\n",
      "       [-0.2243257 , -0.25461598, -0.15610144, -0.2013665 , -0.27637088,\n",
      "         0.11758467, -0.05598428, -0.19819318, -0.03218578,  0.10073191,\n",
      "        -0.06971564,  0.08899198,  0.11876825,  0.01723718, -0.19735764,\n",
      "        -0.13224627,  0.07371006, -0.17527425, -0.1503757 ,  0.24161292],\n",
      "       [-0.02953371,  0.13720513,  0.09180941, -0.17814331, -0.04001339,\n",
      "        -0.14185016, -0.19012058, -0.08942819, -0.12821871, -0.08847979,\n",
      "         0.41297383,  0.1767114 , -0.31441874,  0.15954578,  0.15029917,\n",
      "         0.06842309, -0.0033734 ,  0.28133106, -0.1431427 ,  0.02211975],\n",
      "       [-0.02580743, -0.15601843,  0.10788637, -0.31665429,  0.07691222,\n",
      "         0.17892189,  0.16002991,  0.16377431, -0.07074973, -0.06740318,\n",
      "        -0.07967389,  0.09021676,  0.06495071, -0.18590129,  0.02345703,\n",
      "         0.13487268, -0.03245773,  0.10698773,  0.0447208 ,  0.11969469],\n",
      "       [-0.10410209, -0.04737574,  0.06684416, -0.0127367 ,  0.00409419,\n",
      "         0.12068542,  0.09808976,  0.26640722, -0.14725051,  0.01795334,\n",
      "        -0.23717336,  0.20235321,  0.18172326,  0.12504778, -0.05146059,\n",
      "        -0.05439459, -0.24267043,  0.17941397, -0.09907147, -0.00273372],\n",
      "       [ 0.03843219, -0.29284436, -0.06151704,  0.29389801, -0.10950871,\n",
      "        -0.12682347,  0.07240857, -0.21175364, -0.0827087 , -0.26915424,\n",
      "         0.13507905,  0.21269722, -0.27449196,  0.00084568,  0.18013358,\n",
      "         0.16612481,  0.38180511, -0.16073058,  0.00086028,  0.14812365],\n",
      "       [-0.28557131, -0.25495249,  0.31182031, -0.09072763,  0.00122656,\n",
      "         0.08559305, -0.30593939, -0.05832916,  0.20500612,  0.10920053,\n",
      "        -0.31541949, -0.2511481 ,  0.41844225, -0.16900401, -0.17456262,\n",
      "         0.10790622,  0.0161488 ,  0.06100824, -0.13403455,  0.09228362],\n",
      "       [-0.41077063, -0.02680656,  0.05103498, -0.14193779,  0.083983  ,\n",
      "         0.00806877,  0.21525507, -0.32530253, -0.05375608, -0.04831569,\n",
      "        -0.2007859 ,  0.23342404, -0.25290474,  0.22911509, -0.03184965,\n",
      "        -0.06442172, -0.2428052 , -0.01837534, -0.04854322,  0.14228769],\n",
      "       [-0.06200204,  0.07212629, -0.10328092,  0.03136796, -0.036223  ,\n",
      "         0.18729058,  0.08685199,  0.0253073 , -0.00253416,  0.21898606,\n",
      "        -0.43353914,  0.08871538,  0.25039256, -0.03312954,  0.18254756,\n",
      "        -0.20854058, -0.17968869, -0.21311475, -0.00590604, -0.20384009],\n",
      "       [ 0.08781908,  0.19095916, -0.20597824, -0.24785205,  0.10635467,\n",
      "        -0.11414465,  0.39433302, -0.41333102, -0.22492681, -0.17375589,\n",
      "         0.10198073,  0.11805028, -0.07801869,  0.26159937, -0.13174158,\n",
      "         0.21276791,  0.09387558, -0.09033372, -0.16108169, -0.1082489 ],\n",
      "       [-0.00824353, -0.30423276,  0.099742  , -0.26620597, -0.02687152,\n",
      "        -0.23950739, -0.2195904 ,  0.18253371,  0.07662199, -0.32711464,\n",
      "         0.16106471,  0.0475397 ,  0.29098347,  0.13527802,  0.16557794,\n",
      "         0.03383515,  0.15587953,  0.14929836,  0.06911561,  0.01954703],\n",
      "       [-0.24817555, -0.09750442, -0.1450101 , -0.07747759,  0.2463454 ,\n",
      "         0.1114417 , -0.09482235, -0.0849635 ,  0.12761931, -0.15624811,\n",
      "         0.09241497, -0.08744669,  0.43338876,  0.17697184,  0.146663  ,\n",
      "         0.02649528,  0.20263057, -0.27945857, -0.15082482, -0.18119584],\n",
      "       [-0.19769234, -0.15053285, -0.28108545, -0.13927259,  0.27701748,\n",
      "         0.43680889,  0.07690579,  0.11961021,  0.08207426,  0.04008693,\n",
      "        -0.20998193, -0.08173957,  0.19899685,  0.30825324, -0.08086124,\n",
      "        -0.0787439 ,  0.09471899, -0.11045699, -0.32232958,  0.00887102],\n",
      "       [-0.03805701, -0.20945859,  0.09130162,  0.24842846,  0.05158132,\n",
      "         0.18517616,  0.17731445,  0.11581957,  0.17715628,  0.23686329,\n",
      "        -0.06270223, -0.28607772, -0.26697276,  0.3301442 ,  0.28548885,\n",
      "        -0.08022648, -0.29491872, -0.0258752 ,  0.12860545, -0.08990975],\n",
      "       [-0.05615628, -0.13495383, -0.06821727, -0.07135009,  0.21050046,\n",
      "        -0.18313018, -0.0631325 , -0.09107426, -0.1265589 , -0.18509845,\n",
      "         0.20420803,  0.13696042, -0.10414355,  0.36866032,  0.02393481,\n",
      "        -0.24831172,  0.03922275, -0.0593525 ,  0.03317906,  0.15238908]])>, <tf.Variable 'Variable:0' shape=(20, 20) dtype=float64, numpy=\n",
      "array([[ 0.31194582, -0.13064071, -0.02980152,  0.19577935, -0.05954576,\n",
      "        -0.04700377,  0.1335216 , -0.23830027,  0.08496082, -0.17214824,\n",
      "         0.2003682 ,  0.0482258 ,  0.15234089, -0.12569329,  0.0030991 ,\n",
      "        -0.21698354, -0.22650475,  0.28944028, -0.11867732,  0.08976979],\n",
      "       [-0.00604966,  0.20608289,  0.0268069 , -0.20167712, -0.26380053,\n",
      "        -0.08557643, -0.15307865,  0.06032181,  0.17344971, -0.01685958,\n",
      "        -0.00365294, -0.1112497 , -0.35666529, -0.29017332, -0.12583481,\n",
      "        -0.10507763, -0.06048532,  0.11669985,  0.21686427, -0.27768659],\n",
      "       [-0.1726917 ,  0.44535939, -0.27379069, -0.22733608,  0.22556002,\n",
      "        -0.14703353,  0.36459209,  0.341613  ,  0.36299449,  0.07436286,\n",
      "         0.02709152,  0.06514099,  0.05529706,  0.10275237,  0.28035063,\n",
      "        -0.3377218 , -0.06006576, -0.14483175, -0.18254966,  0.12519567],\n",
      "       [-0.21530921, -0.01088175, -0.41543496,  0.09350159,  0.12476394,\n",
      "         0.25542874, -0.13627385,  0.06583241, -0.18686477,  0.30260451,\n",
      "        -0.25760035, -0.05054213, -0.03856992, -0.25036899, -0.39803965,\n",
      "        -0.33084733, -0.00334123,  0.25414552,  0.04558269, -0.41403381],\n",
      "       [ 0.21316706,  0.05445177,  0.21446855, -0.21884192, -0.09626896,\n",
      "         0.16392914, -0.19658406,  0.07939665,  0.02049043, -0.09396348,\n",
      "        -0.04640593, -0.06844271,  0.24829226,  0.20816   ,  0.33662289,\n",
      "        -0.04064369, -0.17602737, -0.05379766,  0.15489896,  0.14681763],\n",
      "       [-0.33956983,  0.00627375, -0.1098692 ,  0.08128607,  0.30384038,\n",
      "        -0.29906629,  0.07048441,  0.15005964, -0.13908223, -0.0626783 ,\n",
      "         0.09711595,  0.37227869,  0.13256293, -0.04466632,  0.24697783,\n",
      "         0.191524  , -0.36047797, -0.39471157, -0.0928451 ,  0.06015718],\n",
      "       [ 0.27474488, -0.00220826, -0.2552242 , -0.23263548, -0.04689896,\n",
      "         0.11324345,  0.20820303, -0.01922074, -0.40094881, -0.33167127,\n",
      "        -0.31569652, -0.2163875 , -0.08768261,  0.22797738, -0.07010421,\n",
      "         0.18191262,  0.10089208, -0.33639853, -0.21306405, -0.12835151],\n",
      "       [ 0.03007478,  0.04775742,  0.21399924, -0.06495995, -0.33710824,\n",
      "        -0.05867701,  0.12971686, -0.24628579,  0.02291193,  0.02427784,\n",
      "         0.06055995,  0.10121979,  0.14601965, -0.34871938, -0.17150008,\n",
      "         0.02769393, -0.05760582,  0.00765603,  0.37451821, -0.13285899],\n",
      "       [-0.20477642, -0.08740474,  0.09290146,  0.19147857, -0.41098458,\n",
      "         0.1071768 ,  0.2108167 , -0.12727845, -0.0823147 ,  0.06778267,\n",
      "         0.10990135,  0.19904788, -0.18104071, -0.10877781,  0.43847489,\n",
      "        -0.07359434, -0.3066838 , -0.08787423, -0.26366895, -0.25703647],\n",
      "       [-0.11502963,  0.00398674, -0.24777797, -0.04709969,  0.37397143,\n",
      "         0.42072695,  0.0484109 , -0.16399482, -0.01263955, -0.19756528,\n",
      "         0.06936281,  0.43587791,  0.37535587, -0.14030379, -0.12824787,\n",
      "        -0.10697323,  0.23265552,  0.21190013, -0.00963027,  0.03445133],\n",
      "       [-0.00700214,  0.09169319,  0.26934765,  0.12087231,  0.14155751,\n",
      "         0.19984974, -0.0986543 , -0.18618148, -0.34575685,  0.0904929 ,\n",
      "        -0.03327908,  0.13319668, -0.07181071,  0.33044056,  0.16515616,\n",
      "        -0.02782991, -0.43711226,  0.26696374, -0.2104856 ,  0.04612076],\n",
      "       [-0.37051991, -0.25732367, -0.16001432,  0.40387713,  0.05386362,\n",
      "         0.07317824, -0.15242528,  0.11301771, -0.00384441, -0.02680838,\n",
      "         0.43412879, -0.22681372, -0.09140214, -0.27309879,  0.00584731,\n",
      "        -0.3121691 ,  0.00595151, -0.27895979,  0.29880424,  0.20372484],\n",
      "       [-0.13729067, -0.03297039, -0.09938264, -0.13094636, -0.16207929,\n",
      "        -0.33510911, -0.29232188,  0.07096847,  0.05379009,  0.07500363,\n",
      "        -0.33472242,  0.11034767, -0.20146157, -0.32917464, -0.17566338,\n",
      "        -0.24934352, -0.12257343, -0.25371092, -0.09074064, -0.3105642 ],\n",
      "       [ 0.19532909, -0.02862814,  0.20865323, -0.16602326, -0.29553255,\n",
      "         0.03080109, -0.06641813, -0.29232708,  0.06693095,  0.15310008,\n",
      "         0.14657757, -0.12442769, -0.03790786, -0.18464247, -0.22755931,\n",
      "         0.29266336,  0.00427981,  0.16815222, -0.2901299 ,  0.01499158],\n",
      "       [-0.17730304,  0.35929858, -0.00285696, -0.13441008, -0.09112966,\n",
      "        -0.01423931,  0.13094297,  0.14066566, -0.01978415, -0.24927045,\n",
      "         0.00718539,  0.1922383 ,  0.4244396 ,  0.05700781, -0.2534684 ,\n",
      "         0.12771681, -0.04348262,  0.02662411,  0.08465579,  0.11500375],\n",
      "       [ 0.10510049,  0.13018391,  0.16841022,  0.15735869, -0.38868194,\n",
      "         0.12724758, -0.09147068, -0.15589959,  0.03591943, -0.10221957,\n",
      "         0.2265525 , -0.23585947,  0.14822073, -0.23521515, -0.18302841,\n",
      "         0.1285435 ,  0.05856104,  0.35200139,  0.34321305,  0.07074226],\n",
      "       [-0.17583169, -0.31355514, -0.20286993, -0.07579794, -0.06693737,\n",
      "         0.15214613, -0.39690181,  0.22691749,  0.08826452, -0.13729351,\n",
      "        -0.17337445,  0.13606481, -0.1546606 , -0.21712749, -0.09599721,\n",
      "         0.32154226,  0.32350203, -0.26230013, -0.09451462, -0.08520429],\n",
      "       [-0.19496244,  0.13033342,  0.31950883, -0.28845491, -0.25021507,\n",
      "         0.07591048,  0.24670002,  0.09965809,  0.08334686,  0.33834372,\n",
      "        -0.28482568, -0.27087039, -0.26352715, -0.07443579,  0.16373634,\n",
      "        -0.06688005,  0.19031655,  0.1556744 , -0.01679429, -0.14799051],\n",
      "       [ 0.04374999,  0.25645883, -0.21105936, -0.06934283, -0.01203658,\n",
      "         0.0497635 , -0.02174061,  0.02355145,  0.30353577,  0.14039138,\n",
      "        -0.04404361, -0.02738108, -0.06830181,  0.08173072,  0.01471742,\n",
      "        -0.29461549, -0.18778795, -0.3406302 , -0.30637001, -0.19403447],\n",
      "       [ 0.39777997, -0.10907464, -0.18855995, -0.22946951, -0.15510644,\n",
      "         0.3486241 , -0.25315354,  0.09640951, -0.0679324 ,  0.28787141,\n",
      "        -0.11811974, -0.28292363, -0.14891639, -0.09574979, -0.01196365,\n",
      "         0.03391792,  0.20013593, -0.14716246,  0.08815529,  0.17852019]])>, <tf.Variable 'Variable:0' shape=(1, 20) dtype=float64, numpy=\n",
      "array([[-0.1786044 , -0.26666907,  0.46166296, -0.02164144,  0.27849504,\n",
      "         0.25291674,  0.18115722, -0.56486573, -0.10156977, -0.01029308,\n",
      "        -0.01439973,  0.4613249 , -0.6115013 ,  0.19294865, -0.49168919,\n",
      "         0.09819246,  0.48803   ,  0.19493922,  0.0808642 ,  0.08329609]])>], [<tf.Variable 'Variable:0' shape=(20, 1) dtype=float64, numpy=\n",
      "array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]])>, <tf.Variable 'Variable:0' shape=(20, 1) dtype=float64, numpy=\n",
      "array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]])>, <tf.Variable 'Variable:0' shape=(20, 1) dtype=float64, numpy=\n",
      "array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]])>, <tf.Variable 'Variable:0' shape=(20, 1) dtype=float64, numpy=\n",
      "array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]])>, <tf.Variable 'Variable:0' shape=(1, 1) dtype=float64, numpy=array([[0.]])>]]\n"
     ]
    }
   ],
   "source": [
    "all_variables=[model.weights,model.biases]\n",
    "print(all_variables)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
