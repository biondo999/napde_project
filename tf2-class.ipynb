{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pyDOE","metadata":{"execution":{"iopub.status.busy":"2023-05-13T11:18:19.715298Z","iopub.execute_input":"2023-05-13T11:18:19.715861Z","iopub.status.idle":"2023-05-13T11:18:38.027781Z","shell.execute_reply.started":"2023-05-13T11:18:19.715826Z","shell.execute_reply":"2023-05-13T11:18:38.026631Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting pyDOE\n  Downloading pyDOE-0.3.8.zip (22 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pyDOE) (1.23.5)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from pyDOE) (1.9.3)\nBuilding wheels for collected packages: pyDOE\n  Building wheel for pyDOE (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyDOE: filename=pyDOE-0.3.8-py3-none-any.whl size=18184 sha256=e341344e22caa03e4b90eaa4715af567dc1c91765f2a7ae247bfaccc2c5f7ed2\n  Stored in directory: /root/.cache/pip/wheels/ce/b6/d7/c6b64746dba6433c593e471e0ac3acf4f36040456d1d160d17\nSuccessfully built pyDOE\nInstalling collected packages: pyDOE\nSuccessfully installed pyDOE-0.3.8\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"#you need to add a dataset with GaussJacobiQuadRule_V3 on the right \nimport sys\nsys.path.insert(1, '/kaggle/input/quadrule')\nfrom GaussJacobiQuadRule_V3 import Jacobi, DJacobi, GaussLobattoJacobiWeights, GaussJacobiWeights\n\n#import GaussJacobiQuadRule_V3\n\n\nimport tensorflow as tf\n#tf.disable_v2_behavior()\nimport pyDOE\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nfrom pyDOE import lhs\n#from GaussJacobiQuadRule_V3.py import Jacobi, DJacobi, GaussLobattoJacobiWeights, GaussJacobiWeights\nimport time","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-13T12:04:39.587515Z","iopub.execute_input":"2023-05-13T12:04:39.587931Z","iopub.status.idle":"2023-05-13T12:04:39.595647Z","shell.execute_reply.started":"2023-05-13T12:04:39.587901Z","shell.execute_reply":"2023-05-13T12:04:39.594474Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"class parameters:\n    def __init__(self,LR,Opt_Niter,N_Element,N_testfcn,N_Quad,lossb_weight,a,b):\n        self.LR = LR\n        self.Opt_Niter = Opt_Niter + 1\n        self.Opt_tresh = 2e-32\n        self.var_form=2\n        self.N_Element = N_Element\n        self.N_testfcn = N_testfcn #number of test function\n        self.N_Quad = N_Quad    #quadrature points \n        self.lossb_weight = lossb_weight #hyprparameter we may turn it up\n\n        #params for the exact sol and boundary term\n        self.omega = 8*np.pi\n        self.amp = 1\n        self.r1 = 80\n\n        #ingredients for loss\n        [self.x_quad, self.w_quad] = GaussLobattoJacobiWeights(N_Quad, 0, 0)\n        print(self.x_quad.dtype)\n\n        self.test_quad_element = self.Test_fcn(self.N_testfcn, self.x_quad)\n        self.d1test_quad_element, self.d2test_quad_element = self.dTest_fcn(self.N_testfcn, self.x_quad)\n\n\n        [self.x_l, self.x_r] = [a, b]     #modify in the future if you want general (a,b) interval\n        self.delta_x = (self.x_r - self.x_l)/N_Element\n        self.grid = np.asarray([ self.x_l + i*self.delta_x for i in range(self.N_Element+1)])\n\n        #build right side (it doesnt depend on the network)\n\n        self.F_ext_total = []\n        for e in range(self.N_Element):\n            x_quad_element = self.grid[e] + (self.grid[e+1]-self.grid[e])/2*(self.x_quad+1)  #traslation of the element \n\n            jacobian = (self.grid[e+1]-self.grid[e])/2\n            testfcn_element = np.asarray([ self.Test_f(n,self.x_quad)  for n in range(1, self.N_testfcn+1)])\n\n            #this is fh calculated on the real nodal values summed over each real nodal values(which comes form CGL nodes )\n\n            f_quad_element = self.f_ext(x_quad_element)\n            F_ext_element  = jacobian*np.asarray([sum(self.w_quad*f_quad_element*testfcn_element[i]) for i in range(self.N_testfcn)])    \n            F_ext_element = F_ext_element[:,None] \n            self.F_ext_total.append(F_ext_element)\n\n        self.F_ext_total = np.asarray(self.F_ext_total)\n\n\n        self.X_bound = np.asarray([a,b],dtype=np.float64)[:,None]\n        self.u_bound   = self.u_exact(self.X_bound)\n\n    def u_exact(self,x):\n        utemp = 0.1*np.sin(self.omega*x) + np.tanh(self.r1*x)\n        return self.amp*utemp\n\n    def f_ext(self,x):\n        gtemp =  -0.1*(self.omega**2)*np.sin(self.omega*x) - (2*self.r1**2)*(np.tanh(self.r1*x))/((np.cosh(self.r1*x))**2)\n        return -self.amp*gtemp\n\n    def Test_f(self,n,x):\n        test  = Jacobi(n+1,0,0,x) - Jacobi(n-1,0,0,x)\n        return test\n    \n    def Test_fcn(self, N_test,x):\n        test_total = []\n        for n in range(1,N_test+1):  \n            test  = Jacobi(n+1,0,0,x) - Jacobi(n-1,0,0,x)\n            test_total.append(test)\n        return np.asarray(test_total)\n\n    def dTest_fcn(self, N_test,x):  #valuete the first and second derivatives of test functions on a point x \n        d1test_total = []\n        d2test_total = []\n        for n in range(1,N_test+1):  \n            if n==1:\n                d1test = ((n+2)/2)*Jacobi(n,1,1,x)\n                d2test = ((n+2)*(n+3)/(2*2))*Jacobi(n-1,2,2,x)\n                d1test_total.append(d1test)\n                d2test_total.append(d2test)\n            elif n==2:\n                d1test = ((n+2)/2)*Jacobi(n,1,1,x) - ((n)/2)*Jacobi(n-2,1,1,x)\n                d2test = ((n+2)*(n+3)/(2*2))*Jacobi(n-1,2,2,x)\n                d1test_total.append(d1test)\n                d2test_total.append(d2test)    \n            else:\n                d1test = ((n+2)/2)*Jacobi(n,1,1,x) - ((n)/2)*Jacobi(n-2,1,1,x)\n                d2test = ((n+2)*(n+3)/(2*2))*Jacobi(n-1,2,2,x) - ((n)*(n+1)/(2*2))*Jacobi(n-3,2,2,x)\n                d1test_total.append(d1test)\n                d2test_total.append(d2test)    \n        return np.asarray(d1test_total), np.asarray(d2test_total)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T12:24:31.585650Z","iopub.execute_input":"2023-05-13T12:24:31.586091Z","iopub.status.idle":"2023-05-13T12:24:31.617239Z","shell.execute_reply.started":"2023-05-13T12:24:31.586057Z","shell.execute_reply":"2023-05-13T12:24:31.615686Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"params=parameters(0.01,1000,20,30,100,1,-1,1)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T12:24:35.502513Z","iopub.execute_input":"2023-05-13T12:24:35.502974Z","iopub.status.idle":"2023-05-13T12:24:36.090334Z","shell.execute_reply.started":"2023-05-13T12:24:35.502943Z","shell.execute_reply":"2023-05-13T12:24:36.089179Z"},"trusted":true},"execution_count":90,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/special/orthogonal.py:139: RuntimeWarning: invalid value encountered in multiply\n  np.poly1d.__init__(self, poly.coeffs * float(kn))\n","output_type":"stream"},{"name":"stdout","text":"float64\n","output_type":"stream"}]},{"cell_type":"code","source":"class Model(tf.keras.Model):\n  def __init__(self,*kwargs):\n    super().__init__()\n    #structure of the nework maybe implment a general way\n    self.dense1 = tf.keras.layers.Dense(units=16,\n                                        activation='gelu',\n                                        kernel_initializer=tf.random.normal,\n                                        bias_initializer=tf.random.normal)\n    self.dense2 = tf.keras.layers.Dense(units=16,\n                                    activation='gelu',\n                                    kernel_initializer=tf.random.normal,\n                                    bias_initializer=tf.random.normal)\n    self.y = tf.keras.layers.Dense(1)\n    self.history=[]\n    self.params=params\n    \n  def call(self, x, training=True):\n    x = x[:, tf.newaxis]\n    x = self.dense1(x)\n    x = self.dense2(x)\n    x = self.y(x)\n    return tf.squeeze(x, axis=1)\n\n  def net_du(self, x):\n    t = tf.constant(x)\n    with tf.GradientTape() as g:\n      g.watch(x)\n      with tf.GradientTape() as gg:\n        gg.watch(x)\n        y = model(x)\n      dy_dx = gg.gradient(y, x)  # dy_dx = 2 * x\n    d2y_dx2 = g.gradient(dy_dx, x)  # d2y_dx2 = 2\n    return dy_dx,d2y_dx2\n\n  def train(self):\n    variables = self.variables\n    optimizer = tf.optimizers.Adam(learning_rate=0.001)\n    print('-->training_starting')\n    for step in range(self.params.Opt_Niter):\n      with tf.GradientTape() as tape:\n        loss =self.calculate_loss()\n        \n      gradient = tape.gradient(loss, variables)\n      optimizer.apply_gradients(zip(gradient, variables))\n\n      if step % 100 == 0:\n        print(f'Iter: {step}',f'Mean squared error: {loss.numpy():0.6f}')\n        self.history.append(loss)\n        \n  def calculate_loss(self):\n    \n    varloss_total = 0\n    \n    for e in range(self.params.N_Element):\n        F_ext_element  = self.params.F_ext_total[e]\n        Ntest_element  = np.shape(F_ext_element)[0] #for each you have N_testfcn\n        x_quad_element = tf.constant(self.params.grid[e] + (self.params.grid[e+1]-self.params.grid[e])/2*(self.params.x_quad+1))\n        x_b_element    = tf.constant(np.array([[self.params.grid[e]], [self.params.grid[e+1]]]))\n        #to change change integral to the ref segment in (-1,1)\n        jacobian       = (self.params.grid[e+1]-self.params.grid[e])/2\n\n        u_NN_quad_element = model(x_quad_element)\n        \n        d1u_NN_quad_element, d2u_NN_quad_element = self.net_du(x_quad_element)\n\n\n    \n        \"\"\"\"\n        if self.params.var_form == 1:\n            U_NN_element = tf.reshape(tf.stack([-jacobian*tf.reduce_sum(self.wquad*d2u_NN_quad_element*test_quad_element[i]) \\\n                                               for i in range(Ntest_element)]),(-1,1))\n        \"\"\"\n        if self.params.var_form == 2:\n            U_NN_element = tf.reshape(tf.stack([ tf.reduce_sum(self.params.w_quad*d1u_NN_quad_element*self.params.d1test_quad_element[i]) \\\n                                          for i in range(Ntest_element)]),(-1,1)) \n            #i think we are going to use this most of the times \n        \"\"\"\n        if self.params.var_form == 3:\n            U_NN_element = tf.reshape(tf.stack([-1/jacobian*tf.reduce_sum(self.wquad*u_NN_quad_element*d2test_quad_element[i]) \\\n                                               +1/jacobian*tf.reduce_sum(u_NN_bound_element*np.array([-d1test_bound_element[i][0], d1test_bound_element[i][-1]]))  \\\n                                               for i in range(Ntest_element)]),(-1,1))\n        \"\"\"\n        \n        Res_NN_element = U_NN_element - F_ext_element\n        loss_element = tf.reduce_mean(tf.square(Res_NN_element))\n        varloss_total = varloss_total + loss_element\n    \n\n    lossb = tf.reduce_mean(tf.square(model(self.params.X_bound) - self.params.u_bound))  #u_NN_pred is what your network has calc,while u_tf is the real value at the boundary\n    #two losses \n    \n\n    \n    return self.params.lossb_weight *lossb + tf.cast(varloss_total, tf.float32) #casting to fix bugs","metadata":{"execution":{"iopub.status.busy":"2023-05-13T12:44:04.837634Z","iopub.execute_input":"2023-05-13T12:44:04.838005Z","iopub.status.idle":"2023-05-13T12:44:04.862614Z","shell.execute_reply.started":"2023-05-13T12:44:04.837977Z","shell.execute_reply":"2023-05-13T12:44:04.861371Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"model=Model(params)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T12:44:08.144167Z","iopub.execute_input":"2023-05-13T12:44:08.144825Z","iopub.status.idle":"2023-05-13T12:44:08.158118Z","shell.execute_reply.started":"2023-05-13T12:44:08.144784Z","shell.execute_reply":"2023-05-13T12:44:08.156863Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"model.train()","metadata":{"execution":{"iopub.status.busy":"2023-05-13T12:44:09.643498Z","iopub.execute_input":"2023-05-13T12:44:09.644563Z","iopub.status.idle":"2023-05-13T12:46:06.719477Z","shell.execute_reply.started":"2023-05-13T12:44:09.644523Z","shell.execute_reply":"2023-05-13T12:46:06.717872Z"},"trusted":true},"execution_count":129,"outputs":[{"name":"stdout","text":"-->training_starting\nIter: 0 Mean squared error: 586.159302\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[129], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[127], line 43\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m     41\u001b[0m   loss \u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_loss()\n\u001b[0;32m---> 43\u001b[0m gradient \u001b[38;5;241m=\u001b[39m \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(gradient, variables))\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py:1112\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1106\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1107\u001b[0m       composite_tensor_gradient\u001b[38;5;241m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[1;32m   1108\u001b[0m           output_gradients))\n\u001b[1;32m   1109\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[1;32m   1110\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m output_gradients]\n\u001b[0;32m-> 1112\u001b[0m flat_grad \u001b[38;5;241m=\u001b[39m \u001b[43mimperative_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimperative_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_sources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflat_sources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent:\n\u001b[1;32m   1121\u001b[0m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_watched_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape\u001b[38;5;241m.\u001b[39mwatched_variables()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     65\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m unconnected_gradients)\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_TapeGradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py:157\u001b[0m, in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    155\u001b[0m     gradient_name_scope \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m forward_pass_name_scope \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmock_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m grad_fn(mock_op, \u001b[38;5;241m*\u001b[39mout_grads)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/math_grad.py:1458\u001b[0m, in \u001b[0;36m_RealDivGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1456\u001b[0m y \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1457\u001b[0m sx \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39mshape(x)\n\u001b[0;32m-> 1458\u001b[0m sy \u001b[38;5;241m=\u001b[39m \u001b[43marray_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1459\u001b[0m rx, ry \u001b[38;5;241m=\u001b[39m gen_array_ops\u001b[38;5;241m.\u001b[39mbroadcast_gradient_args(sx, sy)\n\u001b[1;32m   1460\u001b[0m x \u001b[38;5;241m=\u001b[39m math_ops\u001b[38;5;241m.\u001b[39mconj(x)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1170\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m iterable_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1169\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m replace_iterable_params(args, kwargs, iterable_params)\n\u001b[0;32m-> 1170\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mapi_dispatcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1172\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m result\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"t=np.array([1,2,3])\nmodel(t)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T12:48:22.151816Z","iopub.execute_input":"2023-05-13T12:48:22.152201Z","iopub.status.idle":"2023-05-13T12:48:22.166753Z","shell.execute_reply.started":"2023-05-13T12:48:22.152172Z","shell.execute_reply":"2023-05-13T12:48:22.165760Z"},"trusted":true},"execution_count":131,"outputs":[{"execution_count":131,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(3,), dtype=float32, numpy=array([-5.346185, -6.553838, -7.684123], dtype=float32)>"},"metadata":{}}]}]}